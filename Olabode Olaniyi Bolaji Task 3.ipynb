{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffdc9223-cf28-4a95-8b7a-f59279b077a3",
   "metadata": {},
   "source": [
    "## Task 3  Pizza Place Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0f707e49-5c01-4db6-bf4b-4fcc4f10f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "78705d13-0065-4d67-91b0-5f05139fb6b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x91 in position 1710: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[247]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load datasets (handle encoding issues)\u001b[39;00m\n\u001b[32m      2\u001b[39m order_details = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtimi\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpizza_sales\u001b[39m\u001b[33m\\\u001b[39m\u001b[33morder_details.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m pizza_types = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mtimi\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDownloads\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mpizza_sales\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mpizza_types.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m orders = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtimi\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpizza_sales\u001b[39m\u001b[33m\\\u001b[39m\u001b[33morders.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m pizzas = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtimi\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpizza_sales\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpizzas.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:574\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:663\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._get_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\codecs.py:325\u001b[39m, in \u001b[36mBufferedIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    323\u001b[39m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[32m    324\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.buffer + \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     (result, consumed) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[32m    327\u001b[39m     \u001b[38;5;28mself\u001b[39m.buffer = data[consumed:]\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0x91 in position 1710: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Load datasets (handle encoding issues)\n",
    "order_details = pd.read_csv(r\"C:\\Users\\timi\\Downloads\\pizza_sales\\order_details.csv\")\n",
    "orders = pd.read_csv(r\"C:\\Users\\timi\\Downloads\\pizza_sales\\orders.csv\")\n",
    "pizzas = pd.read_csv(r\"C:\\Users\\timi\\Downloads\\pizza_sales\\pizzas.csv\", e)\n",
    "pizza_types = pd.read_csv(r\"C:\\Users\\timi\\Downloads\\pizza_sales\\pizza_types.csv\", encoding='latin1')\n",
    "\n",
    "# Preview data\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0391699-e789-4883-95c1-d3bf7f8b404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Orders:\", orders.shape)\n",
    "print(\"Order Details:\", order_details.shape)\n",
    "print(\"Pizzas:\", pizzas.shape)\n",
    "print(\"Pizza Types:\", pizza_types.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef1e6f-6476-428b-ac0b-49093a993f42",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57ab08-aba6-4e53-b6ff-06620ac97c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in Orders:\\n\", orders.isnull().sum())\n",
    "print(\"\\nMissing values in Order Details:\\n\", order_details.isnull().sum())\n",
    "print(\"\\nMissing values in Pizzas:\\n\", pizzas.isnull().sum())\n",
    "print(\"\\nMissing values in Pizza Types:\\n\", pizza_types.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade359f-8a9b-45f5-b39e-6cd185c72d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Orders duplicates:\", orders.duplicated().sum())\n",
    "print(\"Order Details duplicates:\", order_details.duplicated().sum())\n",
    "print(\"Pizzas duplicates:\", pizzas.duplicated().sum())\n",
    "print(\"Pizza Types duplicates:\", pizza_types.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9a815-7aa5-4d7c-b75b-0aca033efe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime\n",
    "orders['date'] = pd.to_datetime(orders['date'])\n",
    "\n",
    "# Extract useful date features\n",
    "orders['day'] = orders['date'].dt.day_name()\n",
    "orders['month'] = orders['date'].dt.month_name()\n",
    "orders['hour'] = pd.to_datetime(\n",
    "orders['time'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "\n",
    "### Cleaned the data by checking for missing values, removing duplicates, and converting date columns into proper datetime format to enable time-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d084f-ccbc-497d-b880-c5bff3a04550",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['date'] = pd.to_datetime(orders['date'])\n",
    "order_details['quantity'] = order_details['quantity'].astype(int)\n",
    "pizzas['price'] = pizzas['price'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76084080-2d22-4613-9d11-e7db891d414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.columns = orders.columns.str.lower().str.strip()\n",
    "order_details.columns = order_details.columns.str.lower().str.strip()\n",
    "pizzas.columns = pizzas.columns.str.lower().str.strip()\n",
    "pizza_types.columns = pizza_types.columns.str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c98808-0851-4712-b77c-3b4fe9eb5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all four tables\n",
    "df = order_details.merge(orders, on='order_id') \\\n",
    "                  .merge(pizzas, on='pizza_id') \\\n",
    "                  .merge(pizza_types, on='pizza_type_id')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f965c7-fc1f-4303-99b0-76e3a7b038ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract additional features\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    "df['month'] = df['date'].dt.month_name()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ed523-85ae-4bb8-ba25-cab4a2d2ab40",
   "metadata": {},
   "source": [
    "## Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827b26b-ad29-4061-b21c-c6cb8bde0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create revenue column\n",
    "df['revenue'] = df['quantity'] * df['price']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d9c38-6472-4f0e-a275-9c4b714f5ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the total revenue/sales?\n",
    "\n",
    "total_revenue = df['revenue'].sum()\n",
    "print(f\"The total revenue is ${total_revenue:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27abf7-84ae-49d3-9ac8-855bec316f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the total quantity sold.\n",
    "\n",
    "total_quantity = df['quantity'].sum()\n",
    "print(f\"The total quantity sold is {total_quantity:,} pizzas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298a383-df5c-4a37-932f-75d8179b8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the total orders.\n",
    "\n",
    "total_orders = df['order_id'].nunique()\n",
    "print(f\"The total number of orders is {total_orders:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af56522-c17b-4120-bf98-0756c6649f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many pizza types do they sell?\n",
    "\n",
    "pizza_types_count = df['name'].nunique()\n",
    "print(f\"The total number of pizza types sold is {pizza_types_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011d8b1-2893-45cf-ab35-1fe6ae503967",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the average price of the pizzas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720e7be-9470-4e2c-9478-e30b8ab6c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "##What are the peak hours of sales?\n",
    "hourly_sales = df.groupby('hour')['revenue'].sum()\n",
    "\n",
    "peak_hour = hourly_sales.idxmax()\n",
    "\n",
    "print(f\"The peak hour of sales is {peak_hour}:00\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c6d56-6cec-4700-9af7-7cfc8ce3a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hourly_sales.plot(kind='bar')\n",
    "plt.title(\"Revenue by Hour\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57be31-0ca4-491f-ba36-6f49e915c294",
   "metadata": {},
   "source": [
    "### The highest revenue is generated during lunch hours, especially around midday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42431df-4123-45e6-9357-3aeabaa5ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the total sales made on each day of the week. \n",
    "sales_by_day = df.groupby('day_of_week')['revenue'].sum().sort_values(ascending=True)\n",
    "\n",
    "day_order = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\",\n",
    "               \"Saturday\"]\n",
    "\n",
    "sales_by_day = sales_by_day.reindex(day_order)\n",
    "sales_table = sales_by_day.reset_index()\n",
    "sales_table.columns = ['Day of Week', 'Total Sales']\n",
    "\n",
    "print(f\"The total sales for each day is in the table below\")\n",
    "display(sales_table)\n",
    "\n",
    "## Which day of the week is when sales are made the most?\n",
    "best_day = sales_by_day.idxmax()\n",
    "print(f\"The day with the highest sales is {best_day}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe141004-f8ed-4e55-b0a4-8f917c8c7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sales_by_day.plot(kind='bar')\n",
    "plt.title(\"Revenue by Day of Week\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac90f37-05ec-4414-b5e9-8efdef9f8980",
   "metadata": {},
   "source": [
    "### Sales are highest on Fridays, indicating strong pre-weekend demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27cd22-ff77-405e-bfbd-0054c683e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the top 5 bestselling pizzas.\n",
    "top_5 = df.groupby('name')['quantity'].sum().sort_values(ascending=False).head(5)\n",
    "\n",
    "top_5_table = top_5.reset_index()\n",
    "top_5_table.columns = ['Name', 'Quantity']\n",
    "\n",
    "print(\"The top 5 bestselling pizzas are:\")\n",
    "display(top_5_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19447594-df95-45e7-8796-16d2e309fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "top_5.plot(kind='bar')\n",
    "plt.title(\"Top 5 Bestselling Pizzas\")\n",
    "plt.xlabel(\"Pizza Name\")\n",
    "plt.ylabel(\"Quantity Sold\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd7379-7708-4118-8787-fffa00547c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the sales made in each month\n",
    "sales_by_month = df.groupby('month')['revenue'].sum().sort_values(ascending=True)\n",
    "\n",
    "month_order = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "               \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "sales_by_month = sales_by_month.reindex(month_order)\n",
    "\n",
    "month_order_table = sales_by_month.reset_index()\n",
    "month_order_table.columns = ['Month', 'Sales']\n",
    "\n",
    "print(f\"The sales made in each month is listed below\")\n",
    "display(month_order_table)\n",
    "\n",
    "best_month = sales_by_month.idxmax()\n",
    "print(f\"The month with the highest sales is {best_month}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908113ee-c7ee-4cb1-b8e6-297df15f5d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sales_by_month.plot(kind='bar')\n",
    "plt.title(\"Revenue by Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d1b55-cc70-4594-88ed-bcb502a2630f",
   "metadata": {},
   "source": [
    "### Any trend noticeable? - Sales show seasonal fluctuations, with noticeable peaks during mid-year months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc0e43-5e2b-433f-b167-081fd6d13e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_5 = df.groupby('name')['quantity'].sum().sort_values(ascending=True).head(5)\n",
    "\n",
    "\n",
    "bottom_5_table = bottom_5.reset_index()\n",
    "bottom_5_table.columns = ['Name', 'Quantity Sold']\n",
    "\n",
    "\n",
    "print(\"The lowest performing pizzas are:\")\n",
    "display(bottom_5_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff206e82-6c24-4c51-a31d-fdb6a3bd4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bottom_5.plot(kind='bar')\n",
    "plt.title(\"Bottom 5 Performing Pizzas\")\n",
    "plt.xlabel(\"Pizza Name\")\n",
    "plt.ylabel(\"Quantity Sold\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4aba33-3814-4d4d-958b-92b1839f7bdf",
   "metadata": {},
   "source": [
    "#### Some pizzas sell significantly less than others and may require marketing promotion or menu review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266550d8-411b-4e7b-a0bd-9195909af4c7",
   "metadata": {},
   "source": [
    "#### The pizza business performs strongest during lunch hours and Fridays.\n",
    "#### Certain pizza types dominate sales, while a few underperform and may need strategic attention.\n",
    "#### Overall revenue remains stable throughout the year with slight seasonal variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04c217-7625-4f02-95a1-780db1ad1991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
